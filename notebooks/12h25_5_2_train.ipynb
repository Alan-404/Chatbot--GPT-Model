{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "from model.gpt import GPT\n",
    "import torch\n",
    "import pickle"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "c:\\Users\\nguye\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tqdm\\auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "with open('./tokenizer/tokenizer.pkl', 'rb') as handle:\n",
    "    tokenizer = pickle.load(handle)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "source": [
    "vocab_size = len(tokenizer.word_index)+1"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "source": [
    "model = GPT(vocab_size=vocab_size, checkpoint='./saved_models/05_02_12h10_gpt')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "source": [
    "with open('./clean/data.pkl', 'rb') as handle:\n",
    "    data = pickle.load(handle)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "source": [
    "data.shape"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(584, 201)"
      ]
     },
     "metadata": {},
     "execution_count": 6
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "source": [
    "data = torch.tensor(data, dtype=torch.int64)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "source": [
    "model.fit(sequences=data, batch_size=15, epochs=5)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch: 1 Batch: 1 Loss: 0.47\n",
      "Epoch: 1 Batch: 16 Loss: 6.66\n",
      "Epoch: 1 Batch: 31 Loss: 6.61\n",
      "Epoch: 2 Batch: 1 Loss: 0.44\n",
      "Epoch: 2 Batch: 16 Loss: 6.61\n",
      "Epoch: 2 Batch: 31 Loss: 6.61\n",
      "Epoch: 3 Batch: 1 Loss: 0.44\n",
      "Epoch: 3 Batch: 16 Loss: 6.60\n",
      "Epoch: 3 Batch: 31 Loss: 6.61\n",
      "Epoch: 4 Batch: 1 Loss: 0.44\n",
      "Epoch: 4 Batch: 16 Loss: 6.60\n",
      "Epoch: 4 Batch: 31 Loss: 6.61\n",
      "Epoch: 5 Batch: 1 Loss: 0.44\n",
      "Epoch: 5 Batch: 16 Loss: 6.60\n",
      "Epoch: 5 Batch: 31 Loss: 6.60\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "source": [
    "model.save_model(\"./saved_models/05_02_12h10_gpt\")"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Your Model Saved at ./saved_models/05_02_12h10_gpt\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "source": [
    "model.fit(sequences=data, batch_size=15, epochs=10)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch: 1 Batch: 1 Loss: 0.44\n",
      "Epoch: 1 Batch: 16 Loss: 6.61\n",
      "Epoch: 1 Batch: 31 Loss: 6.60\n",
      "Epoch: 2 Batch: 1 Loss: 0.44\n",
      "Epoch: 2 Batch: 16 Loss: 6.60\n",
      "Epoch: 2 Batch: 31 Loss: 6.59\n",
      "Epoch: 3 Batch: 1 Loss: 0.44\n",
      "Epoch: 3 Batch: 16 Loss: 6.59\n",
      "Epoch: 3 Batch: 31 Loss: 6.59\n",
      "Epoch: 4 Batch: 1 Loss: 0.44\n",
      "Epoch: 4 Batch: 16 Loss: 6.59\n",
      "Epoch: 4 Batch: 31 Loss: 6.59\n",
      "Epoch: 5 Batch: 1 Loss: 0.44\n",
      "Epoch: 5 Batch: 16 Loss: 6.58\n",
      "Epoch: 5 Batch: 31 Loss: 6.58\n",
      "Epoch: 6 Batch: 1 Loss: 0.44\n",
      "Epoch: 6 Batch: 16 Loss: 6.58\n",
      "Epoch: 6 Batch: 31 Loss: 6.58\n",
      "Epoch: 7 Batch: 1 Loss: 0.44\n",
      "Epoch: 7 Batch: 16 Loss: 6.58\n",
      "Epoch: 7 Batch: 31 Loss: 6.58\n",
      "Epoch: 8 Batch: 1 Loss: 0.44\n",
      "Epoch: 8 Batch: 16 Loss: 6.58\n",
      "Epoch: 8 Batch: 31 Loss: 6.58\n",
      "Epoch: 9 Batch: 1 Loss: 0.44\n",
      "Epoch: 9 Batch: 16 Loss: 6.58\n",
      "Epoch: 9 Batch: 31 Loss: 6.58\n",
      "Epoch: 10 Batch: 1 Loss: 0.44\n",
      "Epoch: 10 Batch: 16 Loss: 6.58\n",
      "Epoch: 10 Batch: 31 Loss: 6.58\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "source": [
    "model.save_model(\"./saved_models/05_02_12h10_gpt\")"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Your Model Saved at ./saved_models/05_02_12h10_gpt\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "source": [
    "model.save_model(\"./saved_models/05_02_12h25_gpt\")"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Your Model Saved at ./saved_models/05_02_12h25_gpt\n"
     ]
    }
   ],
   "metadata": {}
  }
 ],
 "nbformat": 4,
 "nbformat_minor": 2,
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": 3
  },
  "orig_nbformat": 4
 }
}